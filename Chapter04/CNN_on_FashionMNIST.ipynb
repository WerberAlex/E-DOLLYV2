{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_on_FashionMNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WerberAlex/E-DOLLYV2/blob/main/Chapter04/CNN_on_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKXHmN72oSr-"
      },
      "source": [
        "from torchvision import datasets\n",
        "import torch\n",
        "data_folder = '/content/' # This can be any directory you want to download FMNIST to\n",
        "fmnist = datasets.FashionMNIST(data_folder, download=True, train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8quMVIspoXAc"
      },
      "source": [
        "tr_images = fmnist.data\n",
        "tr_targets = fmnist.targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCybp42UoYfD"
      },
      "source": [
        "val_fmnist = datasets.FashionMNIST(data_folder, download=True, train=False)\n",
        "val_images = val_fmnist.data\n",
        "val_targets = val_fmnist.targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wf7B5v_oZpV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeG0gLx4oavL"
      },
      "source": [
        "class FMNISTDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        x = x.float()/255\n",
        "        x = x.view(-1,1,28,28)\n",
        "        self.x, self.y = x, y\n",
        "    def __getitem__(self, ix):\n",
        "        x, y = self.x[ix], self.y[ix]\n",
        "        return x.to(device), y.to(device)\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "from torch.optim import SGD, Adam\n",
        "def get_model():\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, kernel_size=5),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 128, kernel_size=5),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(2048, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 10)\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "    return model, loss_fn, optimizer\n",
        "\n",
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    prediction = model(x)\n",
        "    batch_loss = loss_fn(prediction, y)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return batch_loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    max_values, argmaxes = prediction.max(-1)\n",
        "    is_correct = argmaxes == y\n",
        "    return is_correct.cpu().numpy().tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VxMySqHoyUc"
      },
      "source": [
        "def get_data():\n",
        "    train = FMNISTDataset(tr_images, tr_targets)\n",
        "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    val = FMNISTDataset(val_images, val_targets)\n",
        "    val_dl = DataLoader(val, batch_size=len(val_images), shuffle=True)\n",
        "    return trn_dl, val_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hci-4kOneqRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKIE_sjtpRP6"
      },
      "source": [
        "@torch.no_grad()\n",
        "def val_loss(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    val_loss = loss_fn(prediction, y)\n",
        "    return val_loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2hKhLHQpSqx"
      },
      "source": [
        "trn_dl, val_dl = get_data()\n",
        "model, loss_fn, optimizer = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQmmjw70pUe9"
      },
      "source": [
        "!pip install torch_summary\n",
        "from torchsummary import summary\n",
        "model, loss_fn, optimizer = get_model()\n",
        "summary(model, torch.zeros(1,1,28,28));\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97CcIWOBpXuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2166cb-4239-4371-d437-139c09d0902b"
      },
      "source": [
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "for epoch in range(5):\n",
        "    print(epoch)\n",
        "    train_epoch_losses, train_epoch_accuracies = [], []\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
        "        train_epoch_losses.append(batch_loss)\n",
        "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
        "\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        is_correct = accuracy(x, y, model)\n",
        "        train_epoch_accuracies.extend(is_correct)\n",
        "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
        "\n",
        "    for ix, batch in enumerate(iter(val_dl)):\n",
        "        x, y = batch\n",
        "        val_is_correct = accuracy(x, y, model)\n",
        "        validation_loss = val_loss(x, y, model)\n",
        "    val_epoch_accuracy = np.mean(val_is_correct)\n",
        "\n",
        "    train_losses.append(train_epoch_loss)\n",
        "    train_accuracies.append(train_epoch_accuracy)\n",
        "    val_losses.append(validation_loss)\n",
        "    val_accuracies.append(val_epoch_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9N0n1k0paJx"
      },
      "source": [
        "epochs = np.arange(5)+1\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mticker\n",
        "%matplotlib inline\n",
        "plt.subplot(211)\n",
        "plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
        "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
        "plt.title('Training and validation loss with CNN')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid('off')\n",
        "plt.show()\n",
        "plt.subplot(212)\n",
        "plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
        "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
        "plt.title('Training and validation accuracy with CNN')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.ylim(0.8,1)\n",
        "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
        "plt.legend()\n",
        "plt.grid('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTsjWPuyqNNU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # nécessaire pour 3D\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def plot_conv_filter_3d(conv_layer, filter_index=0, channel_index=0):\n",
        "    \"\"\"\n",
        "    Affiche un filtre convolutionnel en 3D.\n",
        "\n",
        "    conv_layer : nn.Conv2d\n",
        "    filter_index : numéro du filtre à afficher (0 ≤ filter_index < out_channels)\n",
        "    channel_index : canal du filtre à afficher (0 ≤ channel_index < in_channels)\n",
        "    \"\"\"\n",
        "    W = conv_layer.weight.data.cpu().numpy()\n",
        "    filter_weights = W[filter_index, channel_index]  # shape (kernel_h, kernel_w)\n",
        "\n",
        "    h, w = filter_weights.shape\n",
        "    X, Y = np.meshgrid(np.arange(w), np.arange(h))\n",
        "    Z = filter_weights\n",
        "\n",
        "    fig = plt.figure(figsize=(6,5))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.plot_surface(X, Y, Z, cmap='bwr', edgecolor='k', linewidth=0.5)\n",
        "    ax.set_title(f'Filtre {filter_index}, Canal {channel_index}')\n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Poids')\n",
        "    plt.show()\n",
        "\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "# Par exemple, la 2ème couche Conv2d\n",
        "conv_layer = conv_layers[0]\n",
        "\n",
        "plot_conv_filter_3d(conv_layer, filter_index=0, channel_index=0)  # affiche le premier filtre du canal 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "\n",
        "def graphcut_filter_surface(Zsmooth, percentile=70):\n",
        "    \"\"\"\n",
        "    Simule un GraphCut sur une surface lisse en utilisant un seuil basé sur percentile.\n",
        "    Zsmooth : surface lissée (2D numpy array)\n",
        "    percentile : pourcentage de poids à conserver\n",
        "    \"\"\"\n",
        "    threshold = np.percentile(np.abs(Zsmooth), percentile)\n",
        "    mask = np.abs(Zsmooth) >= threshold\n",
        "    Zcut = Zsmooth * mask\n",
        "    return Zcut, mask\n",
        "\n",
        "def plot_conv_surface_with_graphcut(conv_layer, filter_index=0, channel_index=0, smooth_factor=50, percentile=70):\n",
        "    W = conv_layer.weight.data.cpu().numpy()\n",
        "    filter_weights = W[filter_index, channel_index]\n",
        "\n",
        "    h, w = filter_weights.shape\n",
        "    y = np.arange(h)\n",
        "    x = np.arange(w)\n",
        "\n",
        "    # Interpolation lisse\n",
        "    interp_func = RegularGridInterpolator((y, x), filter_weights, method='cubic')\n",
        "    ynew = np.linspace(0, h-1, smooth_factor)\n",
        "    xnew = np.linspace(0, w-1, smooth_factor)\n",
        "    X, Y = np.meshgrid(xnew, ynew)\n",
        "    points = np.array([Y.ravel(), X.ravel()]).T\n",
        "    Zsmooth = interp_func(points).reshape(smooth_factor, smooth_factor)\n",
        "\n",
        "    # GraphCut simplifié\n",
        "    Zcut, mask = graphcut_filter_surface(Zsmooth, percentile=percentile)\n",
        "\n",
        "    # Affichage 3D\n",
        "    fig = plt.figure(figsize=(12,5))\n",
        "\n",
        "    # Surface lisse\n",
        "    ax1 = fig.add_subplot(121, projection='3d')\n",
        "    ax1.plot_surface(X, Y, Zsmooth, cmap='bwr', edgecolor='k', linewidth=0.3)\n",
        "    ax1.set_title(f'Filtre {filter_index} Lissé')\n",
        "    ax1.set_xlabel('X')\n",
        "    ax1.set_ylabel('Y')\n",
        "    ax1.set_zlabel('Poids')\n",
        "\n",
        "    # Surface après GraphCut\n",
        "    ax2 = fig.add_subplot(122, projection='3d')\n",
        "    ax2.plot_surface(X, Y, Zcut, cmap='bwr', edgecolor='k', linewidth=0.3)\n",
        "    ax2.set_title(f'Filtre {filter_index} après GraphCut ({percentile}%)')\n",
        "    ax2.set_xlabel('X')\n",
        "    ax2.set_ylabel('Y')\n",
        "    ax2.set_zlabel('Poids')\n",
        "\n",
        "    plt.show()\n",
        "    return Zcut, mask\n",
        "\n",
        "# Exemple d'utilisation\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "# Par exemple, la 2ème couche Conv2d\n",
        "conv_layer = conv_layers[0]\n",
        "\n",
        "Zcut, mask = plot_conv_surface_with_graphcut(conv_layer, filter_index=2, channel_index=0, smooth_factor=50, percentile=90)\n"
      ],
      "metadata": {
        "id": "2zpHzPoiX5A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcScYzP9YGww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zcut et mask obtenus après GraphCut\n",
        "\n",
        "# matrix_5 : ton kernel 5x5 après GraphCut\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "# Par exemple, la 2ème couche Conv2d\n",
        "conv_layer = conv_layers[0]\n",
        "W = conv_layer.weight.data.cpu().numpy()\n",
        "filter_weights = W[2,0]\n",
        "matrix_5 = filter_weights\n",
        "show_filter(matrix_5, title=\"Filtre avant GraphCut 5x5\")\n",
        "show_filter(kernel_values_5x5, title=\"Filtre après GraphCut 5x5\")"
      ],
      "metadata": {
        "id": "zoEVqh0ZZ5we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_values_5x5 = project_graphcut_to_kernel_values(Zcut, mask, kernel_size=5, method='mean')\n",
        "\n",
        "print(\"Kernel 5x5 avec valeurs projetées :\\n\", kernel_values_5x5)\n",
        "print(\"\\n\")\n",
        "print(matrix_5)"
      ],
      "metadata": {
        "id": "UZmFTMNDYdWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L"
      ],
      "metadata": {
        "id": "aQirSry6egS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_importances(importance_dict):\n",
        "    \"\"\"\n",
        "    Calcule la somme totale des importances dans un dictionnaire imbriqué\n",
        "    importance_dict[layer][out_channel][in_channel] = importance\n",
        "    \"\"\"\n",
        "    total = 0.0\n",
        "    for layer_dict in importance_dict.values():\n",
        "        for out_dict in layer_dict.values():\n",
        "            for val in out_dict.values():\n",
        "                total += val\n",
        "    return total\n",
        "print(sum_importances(L))\n",
        "print(sum_importances(M))"
      ],
      "metadata": {
        "id": "Q-YZVerhu0SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_importance_graphcut(weights, percentile=80, kernel_size=5, method=\"extreme\"):\n",
        "    # GraphCut\n",
        "    Zcut, mask = graphcut_filter_surface(weights, percentile=percentile)\n",
        "\n",
        "    # importance = proportion d’énergie conservée après graphcut\n",
        "    energy_before = np.sum(np.abs(weights))\n",
        "    energy_after = np.sum(np.abs(Zcut * mask))\n",
        "    importance = energy_after / (energy_before + 1e-8)\n",
        "\n",
        "    return importance\n"
      ],
      "metadata": {
        "id": "w1E5AgtNxERP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Créer une copie complète du modèle entraîné\n",
        "model_copy = copy.deepcopy(model)\n",
        "\n",
        "def filter_importance_graphcut(weights, percentile=80, kernel_size=5, method=\"extreme\"):\n",
        "    \"\"\"\n",
        "    Calcule une importance basée sur le ratio d'énergie avant/après GraphCut.\n",
        "    Retourne aussi l'énergie totale avant/après.\n",
        "    \"\"\"\n",
        "    # Conversion CPU numpy\n",
        "    if isinstance(weights, torch.Tensor):\n",
        "        weights = weights.detach().cpu().numpy()\n",
        "\n",
        "    # GraphCut\n",
        "    Zcut, mask = graphcut_filter_surface(weights, percentile=percentile)\n",
        "\n",
        "    # Projection 5x5\n",
        "    kernel_values = project_graphcut_to_kernel_values(Zcut, mask, kernel_size=kernel_size, method=method)\n",
        "\n",
        "    # Importance = proportion d'énergie conservée après GraphCut\n",
        "    energy_before = np.sum(np.abs(weights))\n",
        "    energy_after = np.sum(np.abs(kernel_values))\n",
        "    importance = energy_after / (energy_before + 1e-8)\n",
        "\n",
        "    return importance, energy_before, energy_after\n",
        "\n",
        "\n",
        "def mesure_filter_importance(model, smooth_factor=50, percentile=90, kernel_size=5,\n",
        "                             method='extreme', small_threshold=0.0, save_sparse=True):\n",
        "    \"\"\"\n",
        "    Applique le pipeline GraphCut + projection 5x5 à toutes les Conv2d du modèle.\n",
        "    Retourne trois dictionnaires :\n",
        "      - L : importance basée sur GraphCut\n",
        "      - M : importance brute (somme des poids absolus)\n",
        "      - V : variance des poids par filtre\n",
        "    \"\"\"\n",
        "    L = {}\n",
        "    M = {}\n",
        "    V = {}\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Créer une liste uniquement des modules Conv2d\n",
        "    conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "    for m_idx, m in enumerate(conv_layers):\n",
        "        L[m_idx], M[m_idx], V[m_idx] = {}, {}, {}\n",
        "        with torch.no_grad():\n",
        "            out_channels, in_channels, h, w = m.weight.shape\n",
        "            for oc in range(out_channels):\n",
        "                L[m_idx][oc], M[m_idx][oc], V[m_idx][oc] = {}, {}, {}\n",
        "                for ic in range(in_channels):\n",
        "                    filter_weights = m.weight[oc, ic].cpu().numpy()\n",
        "\n",
        "                    # Importance basée sur GraphCut\n",
        "                    importance_graphcut, energy_before, energy_after = filter_importance_graphcut(\n",
        "                        filter_weights,\n",
        "                        percentile=percentile,\n",
        "                        kernel_size=kernel_size,\n",
        "                        method=method\n",
        "                    )\n",
        "                    L[m_idx][oc][ic] = float(importance_graphcut)\n",
        "\n",
        "                    # Importance brute (somme des poids absolus)\n",
        "                    importance_abs = float(np.sum(np.abs(filter_weights)))\n",
        "                    M[m_idx][oc][ic] = importance_abs\n",
        "\n",
        "                    # Variance des poids\n",
        "                    variance = float(np.var(filter_weights))\n",
        "                    V[m_idx][oc][ic] = variance\n",
        "\n",
        "    return L, M, V\n",
        "\n",
        "\n",
        "def evaluate_model(model, val_dl, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            x, y = x.to(next(model.parameters()).device), y.to(next(model.parameters()).device)\n",
        "            pred = model(x)\n",
        "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += x.size(0)\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "\n",
        "# ---- Exemple d'utilisation ----\n",
        "\n",
        "# Mesurer l'importance des filtres\n",
        "L, M, V = mesure_filter_importance(\n",
        "    model_copy,\n",
        "    smooth_factor=50,\n",
        "    percentile=80,\n",
        "    kernel_size=5,\n",
        "    method='extreme',\n",
        "    small_threshold=0.01,\n",
        "    save_sparse=True\n",
        ")\n",
        "\n",
        "# Évaluer le modèle transformé\n",
        "val_loss, val_acc = evaluate_model(model_copy, val_dl, loss_fn)\n",
        "print(f\"Validation Loss après GraphCut: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Exemple : accéder à une couche, filtre, canal\n",
        "print(\"Importance GraphCut du filtre (couche 0, out=0, in=0):\", L[0][0][0])\n",
        "print(\"Importance brute (abs sum) du filtre (couche 0, out=0, in=0):\", M[0][0][0])\n",
        "print(\"Variance du filtre (couche 0, out=0, in=0):\", V[0][0][0])\n"
      ],
      "metadata": {
        "id": "bEzseg-ccTHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_filter_importance(importance_dict):\n",
        "    \"\"\"\n",
        "    importance_dict[conv_layer_idx][out_channel][in_channel] = importance\n",
        "    Affiche l'importance de chaque filtre par couche sur un même graphe.\n",
        "    \"\"\"\n",
        "    x_vals = []\n",
        "    y_vals = []\n",
        "    labels = []\n",
        "\n",
        "    # parcourir chaque couche et filtre\n",
        "    for layer_idx, layer in importance_dict.items():\n",
        "        for out_ch, out_dict in layer.items():\n",
        "            # sommer sur les canaux d'entrée pour chaque filtre\n",
        "            importance = sum(out_dict.values())\n",
        "            x_vals.append(len(x_vals))  # position sur l'axe x\n",
        "            y_vals.append(importance)\n",
        "            labels.append(f\"L{layer_idx}\")  # annoter la couche\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.bar(x_vals, y_vals, color='skyblue')\n",
        "\n",
        "    # ajouter des séparateurs pour les couches\n",
        "    cum_idx = 0\n",
        "    for layer_idx, layer in importance_dict.items():\n",
        "        plt.axvline(x=cum_idx, color='r', linestyle='--', alpha=0.5)\n",
        "        cum_idx += len(layer)\n",
        "\n",
        "    plt.xlabel(\"Filtres (séparés par couche)\")\n",
        "    plt.ylabel(\"Importance (somme des poids absolus)\")\n",
        "    plt.title(\"Importance des filtres par couche\")\n",
        "    plt.show()\n",
        "plot_filter_importance(L)\n",
        "plot_filter_importance(M)\n",
        "plot_filter_importance(V)"
      ],
      "metadata": {
        "id": "HQc9PxGSnMKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_decile_filter_indices(importance_dict, top_fraction=0.1):\n",
        "    \"\"\"\n",
        "    Retourne les indices des filtres les plus importants.\n",
        "\n",
        "    Args:\n",
        "        importance_dict (dict): dict[layer][out_ch][in_ch] = importance\n",
        "        top_fraction (float): fraction à conserver (0.1 = top 10%)\n",
        "\n",
        "    Returns:\n",
        "        indices (list of tuples): [(layer_idx, out_ch, in_ch), ...]\n",
        "        threshold (float): valeur d'importance minimale pour entrer dans le top\n",
        "    \"\"\"\n",
        "    # Aplatir toutes les importances avec leurs indices\n",
        "    all_items = []\n",
        "    for layer_idx, layer in importance_dict.items():\n",
        "        for out_ch, out_dict in layer.items():\n",
        "            for in_ch, imp in out_dict.items():\n",
        "                all_items.append((layer_idx, out_ch, in_ch, imp))\n",
        "\n",
        "    # Calculer le seuil du top fraction\n",
        "    all_importances = np.array([imp for _, _, _, imp in all_items])\n",
        "    threshold = np.percentile(all_importances, 100 * (1 - top_fraction))\n",
        "\n",
        "    # Sélectionner uniquement les filtres au-dessus du seuil\n",
        "    top_indices = [(l, o, i) for l, o, i, imp in all_items if imp >= threshold]\n",
        "\n",
        "    return top_indices, threshold\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "imUG43yaobwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "\n",
        "def prune_model_by_top_indices_list(model, top_indices_list):\n",
        "    \"\"\"\n",
        "    Crée une copie du modèle en ne conservant que les filtres listés dans top_indices_list.\n",
        "\n",
        "    Args:\n",
        "        model: modèle PyTorch original\n",
        "        top_indices_list: liste de tuples [(layer_idx, out_ch, in_ch), ...] des filtres à conserver\n",
        "\n",
        "    Returns:\n",
        "        model_copy: copie du modèle avec filtres sélectionnés\n",
        "    \"\"\"\n",
        "    model_copy = copy.deepcopy(model)\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Organiser les indices par couche et out_channel\n",
        "    layer_out_to_in = defaultdict(list)\n",
        "    for layer_idx, out_ch, in_ch in top_indices_list:\n",
        "        layer_out_to_in[layer_idx, out_ch].append(in_ch)\n",
        "\n",
        "    # Extraire uniquement les couches Conv2d\n",
        "    conv_layers = [m for m in model_copy.modules() if isinstance(m, nn.Conv2d)]\n",
        "\n",
        "    for layer_idx, conv in enumerate(conv_layers):\n",
        "        out_channels, in_channels, h, w = conv.weight.shape\n",
        "\n",
        "        # Récupérer les out_channels à conserver pour cette couche\n",
        "        out_channels_to_keep = sorted(set(o for l, o in layer_out_to_in.keys() if l == layer_idx))\n",
        "        if not out_channels_to_keep:\n",
        "            continue\n",
        "\n",
        "        # Construire le nouveau poids\n",
        "        new_weight_list = []\n",
        "        new_bias_list = []\n",
        "        for oc in out_channels_to_keep:\n",
        "            in_channels_to_keep = layer_out_to_in[(layer_idx, oc)]\n",
        "            new_weight_list.append(conv.weight[oc, in_channels_to_keep, :, :].clone())\n",
        "            if conv.bias is not None:\n",
        "                new_bias_list.append(conv.bias[oc].clone())\n",
        "\n",
        "        n_out = len(out_channels_to_keep)\n",
        "        n_in = max(len(layer_out_to_in[(layer_idx, oc)]) for oc in out_channels_to_keep)\n",
        "\n",
        "        new_conv = nn.Conv2d(\n",
        "            in_channels=n_in,\n",
        "            out_channels=n_out,\n",
        "            kernel_size=conv.kernel_size,\n",
        "            stride=conv.stride,\n",
        "            padding=conv.padding,\n",
        "            bias=conv.bias is not None,\n",
        "            dilation=conv.dilation\n",
        "        ).to(device)\n",
        "\n",
        "        # Empiler les poids correctement\n",
        "        new_weight = torch.stack([w if w.shape[0]==n_in else torch.cat([w, torch.zeros(n_in - w.shape[0], h, w.shape[1], device=device)]) for w in new_weight_list])\n",
        "        new_conv.weight.data = new_weight.to(device)\n",
        "        if conv.bias is not None:\n",
        "            new_conv.bias.data = torch.tensor(new_bias_list, device=device)\n",
        "\n",
        "        # Remplacer la couche\n",
        "        for i, m in enumerate(model_copy):\n",
        "            if m is conv:\n",
        "                model_copy[i] = new_conv\n",
        "                break\n",
        "\n",
        "    return model_copy\n",
        "top_indices, threshold = top_decile_filter_indices(L, top_fraction=0.5)\n",
        "model_pruned = prune_model_by_top_indices_list(model, top_indices)\n"
      ],
      "metadata": {
        "id": "NfzWSaHh7Xu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_summary\n",
        "from torchsummary import summary\n",
        "summary(model_pruned, torch.zeros(1,1,28,28));"
      ],
      "metadata": {
        "id": "u-YMMD_oeY6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DII8woh0fwJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}